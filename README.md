# WebCrawler
Hace uso de scrapy y selenium para realizar los crawler
Para selenium se recomienda hacer uso de la extension para google chrome, se puede descargar del siguiente link
https://selenium-python.readthedocs.io/installation.html#drivers

Configuracion de linux:
  Se descarga el tar.gz y se descomprime en el directorio /usr/bin

En el script main.py, se encuentra la descripcion obtener los links y nombre de cada resultado.
Se encuentra configurado para realizar la busqueda en los siguientes buscadores:
  Google
  Bing
  Yahoo
  
